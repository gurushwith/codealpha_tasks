import requests
from bs4 import BeautifulSoup
import pandas as pd

# Step 1: Define the URL
url = 'http://quotes.toscrape.com'

# Step 2: Send the HTTP request
response = requests.get(url)

# Step 3: Parse the page content with BeautifulSoup
soup = BeautifulSoup(response.text, 'html.parser')

# Step 4: Find all quote blocks
quote_blocks = soup.find_all('div', class_='quote')

# Step 5: Extract quote, author, and tags
quotes_data = []

for quote in quote_blocks:
    text = quote.find('span', class_='text').get_text(strip=True)
    author = quote.find('small', class_='author').get_text(strip=True)
    tag_elements = quote.find_all('a', class_='tag')
    tags = [tag.get_text(strip=True) for tag in tag_elements]
    
    quotes_data.append({
        'Quote': text,
        'Author': author,
        'Tags': ', '.join(tags)
    })

# Step 6: Save to CSV
df = pd.DataFrame(quotes_data)
df.to_csv('quotes.csv', index=False)

# Step 7: Show sample data
print("Scraping successful! Sample data:")
print(df.head())
